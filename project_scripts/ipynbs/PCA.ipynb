{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, normalize, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_PATH = '../../raw_data/cristiano_cfdnas/meta_data.csv'\n",
    "CRISTIANO_PAPER = 'Genome-wide cell-free DNA fragmentation in patients with cancer'\n",
    "\n",
    "def parse_metadata(file_path, paper):\n",
    "    metadata_df = pd.read_csv(file_path)\n",
    "    metadata_df = metadata_df[metadata_df.publication == paper]\n",
    "    return dict(zip(metadata_df.sample_file_id, metadata_df.sample_disease))\n",
    "\n",
    "metadata = parse_metadata(METADATA_PATH, CRISTIANO_PAPER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(matrix, binary_labels, dhs_sites, stat_name):\n",
    "    labels_set = set(binary_labels)\n",
    "    for dhs in set(dhs_sites):\n",
    "        mask = np.array(dhs_sites) == dhs\n",
    "        filtered_matrix = matrix[mask]\n",
    "        \n",
    "        if stat_name == 'pfe':\n",
    "            df = pd.DataFrame({\n",
    "                'value': filtered_matrix.flatten(),\n",
    "                'category': np.array(dhs_sites)[mask],\n",
    "            })\n",
    "\n",
    "            categories = sorted(df['category'].unique())\n",
    "            data_to_plot = [df[df['category'] == cat]['value'].values for cat in categories]\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.violinplot(data_to_plot)\n",
    "            plt.title('Distribution of PFE by DHS')\n",
    "            plt.xlabel('DHS')\n",
    "            plt.ylabel('PFE value')\n",
    "            plt.xticks(ticks=np.arange(1, len(categories) + 1), labels=categories)\n",
    "            plt.tight_layout()\n",
    "            out_path_violin = os.path.join(PCA_PLOT_DIR, f\"{stat_name}_{dhs}_violon.png\")\n",
    "            plt.savefig(out_path_violin, dpi=200)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            pca = PCA(n_components=10)\n",
    "            X_pca = pca.fit_transform(filtered_matrix)\n",
    "            expl_var = pca.explained_variance_ratio_\n",
    "\n",
    "            for group in labels_set:\n",
    "                mask = np.array(binary_labels) == group\n",
    "                x_positions, y_positions = X_pca[mask, 0], X_pca[mask, 1]\n",
    "                plt.scatter(\n",
    "                    x_positions,\n",
    "                    y_positions,\n",
    "                    label=group,\n",
    "                    alpha=0.4\n",
    "                )\n",
    "\n",
    "            plt.xlabel(f\"PC1 ({expl_var[0]*100:.1f}% var)\")\n",
    "            plt.ylabel(f\"PC2 ({expl_var[1]*100:.1f}% var)\")\n",
    "            plt.title(f\"PCA of {stat_name.upper()}\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "            plt.tight_layout()\n",
    "            out_path = os.path.join(PCA_PLOT_DIR, f\"{stat_name}_{dhs}_pca.png\")\n",
    "            plt.savefig(out_path, dpi=200)\n",
    "            plt.close()\n",
    "\n",
    "            pc1_weights = pca.components_[0]\n",
    "            num_weights = len(pc1_weights)\n",
    "            feature_indices = np.arange(num_weights)\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(feature_indices, pc1_weights)\n",
    "            plt.axvline(x=num_weights//2, color='red', linestyle='--', linewidth=2, label='DHS site window')\n",
    "            plt.xlabel(\"Feature Index\")\n",
    "            plt.ylabel(\"Weight in PC1\")\n",
    "            plt.title(f\"PC1 Feature Weights for {stat_name.upper()}\")\n",
    "            plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            out_path_weights = os.path.join(PCA_PLOT_DIR, f\"{stat_name}_{dhs}_pc1_weights.png\")\n",
    "            plt.savefig(out_path_weights, dpi=200)\n",
    "            plt.close()\n",
    "\n",
    "        \n",
    "DATA_DIR = \"../../data/test_small/\"\n",
    "PCA_PLOT_DIR = \"../../data/pca_test_small/\"\n",
    "DHS_FOLDER = '../../raw_data/dhs_one'\n",
    "\n",
    "os.makedirs(PCA_PLOT_DIR, exist_ok=True)\n",
    "\n",
    "DHS_FILES = [f.split('.')[0] for f in os.listdir(DHS_FOLDER)]\n",
    "\n",
    "\n",
    "# hardcoded stats\n",
    "STATS = {\n",
    "    \"ocf\":   (\"{sid}__{dhs}_sorted_ocf.npy\", None),\n",
    "    \"lwps\":  (\"{sid}__{dhs}_sorted_lwps.npy\", None),\n",
    "    \"ifs\":   (\"{sid}__{dhs}_sorted_ifs.npz\", \"ifs_scores\"),\n",
    "    \"pfe\":   (\"{sid}__{dhs}_sorted_pfe.npz\", \"pfe_scores\"),\n",
    "    \"fdi\":   (\"{sid}__{dhs}_sorted_fdi.npz\", \"overlapping_fdi_scores\"),\n",
    "}\n",
    "\n",
    "\n",
    "def load_vectors(stat_name, metadata_cache):\n",
    "    vectors, binary_labels, dhs_sites = [], [], []\n",
    "    \n",
    "    for sid, group_name in metadata_cache.items():\n",
    "        for dhs_name in DHS_FILES:\n",
    "            pattern, key = STATS[stat_name]\n",
    "            fname = pattern.format(sid=sid, dhs=dhs_name)\n",
    "            path = os.path.join(DATA_DIR, fname)\n",
    "\n",
    "            try:\n",
    "                # load npy or npz\n",
    "                if path.endswith(\".npy\"):\n",
    "                    vec = np.load(path)\n",
    "                elif path.endswith(\".npz\"):\n",
    "                    data = np.load(path)\n",
    "                    vec = data[key]\n",
    "                else:\n",
    "                    continue\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            vectors.append(vec.flatten())\n",
    "            binary_labels.append('Healthy' if group_name == 'Healthy' else 'Cancerous')\n",
    "            dhs_sites.append(dhs_name)\n",
    "    \n",
    "    if not vectors:\n",
    "        return None, None, None\n",
    "    matrix = np.vstack(vectors)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(matrix)\n",
    "    matrix = scaler.transform(matrix)\n",
    "    return matrix, binary_labels, dhs_sites\n",
    "\n",
    "\n",
    "all_matrices = defaultdict()\n",
    "all_binary_labels = defaultdict()\n",
    "all_dhs_sites = defaultdict()\n",
    "for stat in STATS.keys():\n",
    "    print(f\"\\nProcessing: {stat}\")\n",
    "    matrix, binary_labels, dhs_sites = load_vectors(stat, metadata)\n",
    "    if matrix is not None:\n",
    "        plot_pca(matrix, binary_labels, dhs_sites, stat)\n",
    "        all_matrices[stat] = matrix\n",
    "        all_binary_labels[stat] = binary_labels\n",
    "        all_dhs_sites[stat] = dhs_sites\n",
    "    else:\n",
    "        print(f\"Skipping {dhs} | {stat} — no data found.\")\n",
    "        \n",
    "# combine by test statistics\n",
    "# combined_matrix = np.hstack(all_matrices)\n",
    "\n",
    "X = combined_matrix\n",
    "y_strings = np.array(all_labels)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_strings)\n",
    "print(f\"Label mapping: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "n_pca_components = 10\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=n_pca_components)),\n",
    "    ('classifier', SVC(probability=True, random_state=42)),\n",
    "])\n",
    "\n",
    "n_splits = 10\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Mean Accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'value': all_matrices['pfe'].flatten(),\n",
    "    'category': all_dhs_sites['pfe'],\n",
    "    'binary_labels': all_binary_labels['pfe'],\n",
    "})\n",
    "\n",
    "categories = sorted(df['category'].unique())\n",
    "data_to_plot = [df[df['category'] == cat]['value'].values for cat in categories]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.violinplot(data_to_plot)\n",
    "plt.title('Distribution of Values by Category')\n",
    "plt.xlabel(\"all_dhs_sites['pfe'] Category\")\n",
    "plt.ylabel(\"all_matrices['pfe'] Value\")\n",
    "plt.xticks(ticks=np.arange(1, len(categories) + 1), labels=categories)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_dhs_sites['ocf']) == 'Healthy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine by test statistics\n",
    "combined_matrix = np.hstack(all_matrices)\n",
    "\n",
    "X = combined_matrix\n",
    "y_strings = np.array(all_binary_labels)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_strings)\n",
    "print(f\"Label mapping: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "n_pca_components = 10\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=n_pca_components)),\n",
    "#     ('classifier', LDA()),\n",
    "    ('classifier', SVC(probability=True, random_state=42)),\n",
    "])\n",
    "\n",
    "n_splits = 10\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Mean Accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counter = Counter(all_labels)\n",
    "plt.bar(label_counter.keys(), label_counter.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Multi-label classes\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Distribution of multi-label classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_label_counter = Counter(all_binary_labels)\n",
    "plt.bar(binary_label_counter.keys(), binary_label_counter.values())\n",
    "plt.xlabel(\"Binary classes\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Distribution of binary classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_matrix.shape, len(all_labels), len(all_binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdi_meta_path = '../../data/cristiano_cfdnas_dhs_small/feature_matrix_fdi_meta.npz'\n",
    "# fdi_path = '../../data/cristiano_cfdnas_dhs_small/feature_matrix_fdi.npy'\n",
    "\n",
    "feature_dir = '../../data/cristiano_cfdnas_dhs_small/'\n",
    "\n",
    "\n",
    "def load_stat(stat: str, feature_dir: str):\n",
    "    matrix_path = os.path.join(feature_dir, f\"feature_matrix_{stat}.npy\")\n",
    "    meta_path = os.path.join(feature_dir, f\"feature_matrix_{stat}_meta.npz\")\n",
    "    if not (os.path.exists(matrix_path) and os.path.exists(meta_path)):\n",
    "        return None\n",
    "    X = np.load(matrix_path)\n",
    "    meta = np.load(meta_path)\n",
    "    dhs_sites = meta['dhs_sites']\n",
    "\n",
    "    labels = meta['binary_labels'] if 'binary_labels' in meta else None\n",
    "    sample_ids = meta['sample_ids'] if 'sample_ids' in meta else None\n",
    "    return X, dhs_sites, labels, sample_ids\n",
    "\n",
    "\n",
    "def build_pc1_feature_matrix(X, dhs_sites, sample_ids):\n",
    "    unique_samples = np.unique(sample_ids)\n",
    "    unique_dhs = np.unique(dhs_sites)\n",
    "\n",
    "    # map sample to index for final assembly\n",
    "    sample_index = {s: i for i, s in enumerate(unique_samples)}\n",
    "    # for each DHS, collect vectors for all samples -> matrix (n_samples x n_features) then PCA-> PC1 per sample\n",
    "    pc1_columns = []\n",
    "    valid_dhs = []\n",
    "    for dhs in unique_dhs:\n",
    "        mask = dhs_sites == dhs\n",
    "        dhs_samples = sample_ids[mask]\n",
    "        dhs_vectors = X[mask]\n",
    "        if len(np.unique(dhs_samples)) != len(unique_samples):\n",
    "            # skip DHS if incomplete (could also impute)\n",
    "            continue\n",
    "        # order rows by global sample ordering\n",
    "        order = np.argsort([sample_index[s] for s in dhs_samples])\n",
    "        dhs_matrix = dhs_vectors[order]\n",
    "        # standardize per feature\n",
    "        dhs_matrix = StandardScaler().fit_transform(dhs_matrix)\n",
    "        pca = PCA(n_components=1)\n",
    "        pc1 = pca.fit_transform(dhs_matrix).ravel()  # length n_samples\n",
    "        pc1_columns.append(pc1)\n",
    "        valid_dhs.append(dhs)\n",
    "    if not pc1_columns:\n",
    "        return None, None, None\n",
    "    pc1_matrix = np.vstack(pc1_columns).T  # shape (n_samples, n_valid_dhs)\n",
    "    return pc1_matrix, np.array(valid_dhs), unique_samples\n",
    "\n",
    "\n",
    "def evaluate_stat_pc1(stat: str, feature_dir: str, cv_splits: int):\n",
    "    loaded = load_stat(stat, feature_dir)\n",
    "    if loaded is None:\n",
    "        return None\n",
    "    X, dhs_sites, labels, sample_ids = loaded\n",
    "    if labels is None or sample_ids is None:\n",
    "        return None\n",
    "\n",
    "    pc1_matrix, valid_dhs, unique_samples = build_pc1_feature_matrix(X, dhs_sites, sample_ids)\n",
    "    if pc1_matrix is None:\n",
    "        return None\n",
    "    \n",
    "    print(pc1_matrix.shape, X.shape)\n",
    "\n",
    "    # build per-sample labels\n",
    "    sample_label_map = {}\n",
    "    for sid, lab in zip(sample_ids, labels):\n",
    "        if sid not in sample_label_map:\n",
    "            sample_label_map[sid] = lab\n",
    "    y_strings = [sample_label_map[s] for s in unique_samples]\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "    \n",
    "    n_pca_components = 1\n",
    "    pipeline = Pipeline([\n",
    "        ('pca', PCA(n_components=n_pca_components)),\n",
    "        ('classifier', SVC(probability=True, random_state=42)),\n",
    "    ])\n",
    "\n",
    "    n_splits = 10\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    print(f\"Mean ROC-AUC: {np.mean(scores):.3f} ± {np.std(scores):.3f}\")\n",
    "\n",
    "\n",
    "    # classification on pc1_matrix\n",
    "#     clf = SVC(kernel='linear', probability=True, random_state=42)\n",
    "#     cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "\n",
    "#     auc_scores = []\n",
    "#     for train_idx, test_idx in cv.split(pc1_matrix, y):\n",
    "#         clf.fit(pc1_matrix[train_idx], y[train_idx])\n",
    "#         probs = clf.predict_proba(pc1_matrix[test_idx])\n",
    "#         print(probs[:, 1].shape, y[test_idx].shape)\n",
    "#         if probs.shape[1] == 2:\n",
    "#             auc = roc_auc_score(y[test_idx], probs[:, 1])\n",
    "#         else:\n",
    "#             auc = roc_auc_score(y[test_idx], probs, multi_class='ovr')\n",
    "#         auc_scores.append(auc)\n",
    "\n",
    "#     return {\n",
    "#         'stat': stat,\n",
    "#         'auc_mean': float(np.mean(auc_scores)),\n",
    "#         'auc_std': float(np.std(auc_scores)),\n",
    "#         'n_dhs_used': int(len(valid_dhs)),\n",
    "#     }\n",
    "\n",
    "\n",
    "r = evaluate_stat_pc1('fdi', feature_dir, 10)\n",
    "r\n",
    "# if r is not None:\n",
    "#     results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdi_meta_path = '../../data/cristiano_cfdnas_dhs_small/feature_matrix_fdi_meta.npz'\n",
    "# fdi_path = '../../data/cristiano_cfdnas_dhs_small/feature_matrix_fdi.npy'\n",
    "\n",
    "feature_dir = '../../data/cristiano_cfdnas_dhs_small/'\n",
    "\n",
    "\n",
    "def load_stat(stat: str, feature_dir: str):\n",
    "    matrix_path = os.path.join(feature_dir, f\"feature_matrix_{stat}.npy\")\n",
    "    meta_path = os.path.join(feature_dir, f\"feature_matrix_{stat}_meta.npz\")\n",
    "    if not (os.path.exists(matrix_path) and os.path.exists(meta_path)):\n",
    "        return None\n",
    "    X = np.load(matrix_path)\n",
    "    meta = np.load(meta_path)\n",
    "\n",
    "    labels = meta['binary_labels'] if 'binary_labels' in meta else None\n",
    "    return X, labels\n",
    "\n",
    "\n",
    "def evaluate_stat_pc1(stat: str, feature_dir: str, cv_splits: int):\n",
    "    loaded = load_stat(stat, feature_dir)\n",
    "    if loaded is None:\n",
    "        return None\n",
    "    X, labels = loaded\n",
    "    if labels is None:\n",
    "        return None\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "    \n",
    "    n_pca_components = 1\n",
    "    pipeline = Pipeline([\n",
    "        ('pca', PCA(n_components=n_pca_components)),\n",
    "        ('classifier', SVC(probability=True, random_state=42)),\n",
    "    ])\n",
    "\n",
    "    n_splits = 10\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    return {\n",
    "        'stat': stat,\n",
    "        'auc_mean': float(np.mean(scores)),\n",
    "        'auc_std': float(np.std(scores)),\n",
    "    }\n",
    "\n",
    "\n",
    "stats = ['fdi', 'pfe', 'ocf', 'lwps', 'ifs']\n",
    "cv_splits = 10\n",
    "\n",
    "results = []\n",
    "for stat in stats:\n",
    "    r = evaluate_stat_pc1(stat, feature_dir, cv_splits)\n",
    "    if r is not None:\n",
    "        results.append(r)\n",
    "\n",
    "if results:\n",
    "    stats_order = [r['stat'] for r in results]\n",
    "    auc_means = [r['auc_mean'] for r in results]\n",
    "    auc_stds = [r['auc_std'] for r in results]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bars = plt.bar(stats_order, auc_means, yerr=auc_stds, capsize=5)\n",
    "    plt.ylabel('Mean ROC AUC (PC1 across DHS)')\n",
    "    plt.xlabel('Test statistic')\n",
    "    for bar, val in zip(bars, auc_means):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width()/2 - 0.05,\n",
    "            bar.get_height(), \n",
    "            f\"{val:.2f}\", \n",
    "            ha='right', \n",
    "            va='bottom', \n",
    "            fontsize=9\n",
    "        )\n",
    "    plt.title('Binary classification result (PC1 features + SVM)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
