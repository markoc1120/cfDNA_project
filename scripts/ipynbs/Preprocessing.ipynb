{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "# zcat EE87920.hg38.frag.gz | awk -F'\\t' '{print $3 - $2}' | sort -nr | head -n 1 -> 262\n",
    "MATRIX_ROWS = int(262 * 1.01)  # add 50% threshold\n",
    "MATRIX_COLUMNS = 2000\n",
    "MATRIX_COLUMNS_HALF = MATRIX_COLUMNS // 2\n",
    "\n",
    "\n",
    "TEST_DATA = \"../../data/sorted/breast_sorted.hg38.frag.gz\"\n",
    "DHS_DATA = \"../../data/sorted/Lymphoid_DHS_sorted.bed\"\n",
    "\n",
    "\n",
    "def read_dhs_to_memory():\n",
    "    # saving DHS midpoints in a queue ds (in memory)\n",
    "    sites = deque()\n",
    "    with open(DHS_DATA, 'rt') as f:\n",
    "        # keeping track of last_midpoint to decide whether the next DHS is inside the window or not, \n",
    "        #as well as curr_chr, because if we change chr then we need to reset last_midpoint\n",
    "        last_midpoint, curr_chr = float('-inf'), None\n",
    "        \n",
    "        # line by line iteration\n",
    "        for i, line in enumerate(f):\n",
    "            chr, start, end = line.split('\\t')\n",
    "            \n",
    "            # reset variables\n",
    "            if chr != curr_chr:\n",
    "                last_midpoint, curr_chr = float('-inf'), chr\n",
    "            \n",
    "            # parse string -> int\n",
    "            start, end = int(start), int(end)\n",
    "            midpoint = (end + start) // 2\n",
    "            \n",
    "            # if there is not enough diff between midpoint (current) and last_midpoint -> overlapping -> continue\n",
    "            if midpoint - last_midpoint <= MATRIX_COLUMNS:\n",
    "                # logger.info('skip - overlapping')\n",
    "                continue\n",
    "            \n",
    "            # save midpoint (current)\n",
    "            sites.append((midpoint, chr))\n",
    "            # set last_midpoint to midpoint (current)\n",
    "            last_midpoint = midpoint\n",
    "    return sites, len(sites)\n",
    "    \n",
    "\n",
    "def get_curr_dhs() -> tuple:\n",
    "    if not DHS_sites:\n",
    "        return None, None, None\n",
    "    \n",
    "    curr_dhs_midpoint, chr = DHS_sites.popleft()\n",
    "    return (\n",
    "        curr_dhs_midpoint - MATRIX_COLUMNS_HALF, \n",
    "        curr_dhs_midpoint + MATRIX_COLUMNS_HALF,\n",
    "        chr\n",
    "    )\n",
    "\n",
    "def parse_fragment(line: str) -> tuple:\n",
    "    parsed_fragment = line.strip().split('\\t')\n",
    "    chr, start, end = parsed_fragment[0:3]\n",
    "    return chr, int(start), int(end)\n",
    "\n",
    "DHS_sites, initial_DHS_length = read_dhs_to_memory()\n",
    "\n",
    "result = np.zeros((MATRIX_ROWS, MATRIX_COLUMNS))\n",
    "curr_dhs_start, curr_dhs_end, curr_chr = get_curr_dhs()\n",
    "with gzip.open(TEST_DATA, 'rt') as f:\n",
    "    for line in f:\n",
    "        chr, start, end = parse_fragment(line)\n",
    "        fragment_midpoint, fragment_length = (start + end) // 2, end - start\n",
    "        \n",
    "        # if the fragment is too long skip and log it for now\n",
    "        if fragment_length >= MATRIX_ROWS:\n",
    "            logger.warning(f'Skipped fragment due to too high length:\\nstart:{start}\\nend:{end}')\n",
    "            continue\n",
    "        \n",
    "        # move dhs until to the fragments' chromosome is reached\n",
    "        while curr_dhs_end and chr != curr_chr:\n",
    "            curr_dhs_start, curr_dhs_end, curr_chr = get_curr_dhs()\n",
    "            if curr_dhs_end is None:\n",
    "                logger.warning('No more DHS sites')\n",
    "                break\n",
    "        \n",
    "        # move dhs until we have overlapping fragments\n",
    "        while curr_dhs_end and chr == curr_chr and fragment_midpoint > curr_dhs_end:\n",
    "            curr_dhs_start, curr_dhs_end, curr_chr = get_curr_dhs()\n",
    "            if curr_dhs_end is None:\n",
    "                logger.warning('No more DHS sites')\n",
    "                break\n",
    "                \n",
    "        # break if no more dhs sites\n",
    "        if curr_dhs_end is None:\n",
    "            logger.warning('No more DHS sites')\n",
    "            break\n",
    "            \n",
    "        # move fragments that are not overlapping and in the previous chromosome from the dhs point of view\n",
    "        if chr != curr_chr:\n",
    "            continue\n",
    "            \n",
    "        rel_midpoint = fragment_midpoint - curr_dhs_start\n",
    "\n",
    "        if rel_midpoint >= 0 and rel_midpoint < MATRIX_COLUMNS:\n",
    "            result[fragment_length, rel_midpoint] += 1\n",
    "        \n",
    "        \n",
    "# saving result\n",
    "# np.save('../../data/test/EE87920__Lymphoid_DHS_sorted.npy', result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# opening numpy arrays\n",
    "# with open('../../data/test/EE87920__Lymphoid_DHS_sorted.npy', 'rb') as f:\n",
    "#     a = np.load(f)\n",
    "    \n",
    "# a, a.shape, a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fragment_lengths = result.sum(axis=1)\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 4))\n",
    "plt.plot(np.arange(len(fragment_lengths)), fragment_lengths)\n",
    "plt.xlabel(\"Fragment lengths\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Fragment lengths distribution\")\n",
    "# plt.show()\n",
    "# fig.savefig('temp.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length vs fragments' relative midpoint\n",
    "def calculate_coverage(result: np.ndarray, max_position: int) -> np.ndarray:\n",
    "    coverage = np.zeros(max_position)\n",
    "    \n",
    "    for fragment_length in range(result.shape[0]):\n",
    "        for rel_midpoint in range(result.shape[1]):\n",
    "            count = result[fragment_length, rel_midpoint]\n",
    "            if count > 0:\n",
    "                # calculate start and end positions from midpoint and length\n",
    "                start_pos = rel_midpoint - fragment_length // 2\n",
    "                end_pos = rel_midpoint + fragment_length // 2\n",
    "                \n",
    "                # make sure we stay in our boundaries\n",
    "                start_pos = max(0, start_pos)\n",
    "                end_pos = min(max_position, end_pos)\n",
    "                \n",
    "                # update coverage\n",
    "                if start_pos < end_pos:\n",
    "                    coverage[start_pos:end_pos] += count\n",
    "    \n",
    "    return coverage\n",
    "\n",
    "coverage = calculate_coverage(result, MATRIX_COLUMNS)\n",
    "coverage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(coverage)), coverage)\n",
    "plt.xlabel(\"Relative midpoint positions\")\n",
    "plt.ylabel(\"Coverage\")\n",
    "plt.title(\"Relative midpoint positions VS Coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LWPS_WINDOW_SIZE = 120\n",
    "LWPS_LOWER_THRESHOLD = 120\n",
    "LWPS_UPPER_THRESHOLD = 180\n",
    "NUM_POSITIONS = MATRIX_COLUMNS - 2 * LWPS_UPPER_THRESHOLD\n",
    "\n",
    "def calculate_lwps(result: np.ndarray, window_size=LWPS_WINDOW_SIZE) -> np.ndarray:\n",
    "    lwps = np.zeros(NUM_POSITIONS)\n",
    "    \n",
    "    # precompute fragment_data to avoid O(n^3)\n",
    "    fragment_data = []\n",
    "    for fragment_length in range(result.shape[0]):\n",
    "        # filtering out fragments for 120-180 bp length range\n",
    "        if LWPS_LOWER_THRESHOLD <= fragment_length <= LWPS_UPPER_THRESHOLD:\n",
    "            continue\n",
    "            \n",
    "        for rel_midpoint in range(result.shape[1]):\n",
    "            count = result[fragment_length, rel_midpoint]\n",
    "            if count > 0:\n",
    "                frag_start = rel_midpoint - fragment_length // 2\n",
    "                frag_end = rel_midpoint + fragment_length // 2\n",
    "                fragment_data.append({\n",
    "                    'start': frag_start,\n",
    "                    'end': frag_end,\n",
    "                    'count': count,\n",
    "                })\n",
    "                \n",
    "    # sliding window -> calculating lwps for each positions 180,181,...,1818, 1819 O(n^2)\n",
    "    for pos in range(LWPS_UPPER_THRESHOLD, NUM_POSITIONS + LWPS_UPPER_THRESHOLD):\n",
    "        # matrix indexing starts from 0\n",
    "        pos_idx = pos - LWPS_UPPER_THRESHOLD\n",
    "        \n",
    "        if pos_idx % 100 == 0 or pos_idx == NUM_POSITIONS - 1:\n",
    "            progress = pos_idx / NUM_POSITIONS * 100\n",
    "            logger.info(f\"Progress: {progress:.1f}%\")\n",
    "        \n",
    "        # for position 0 -> window [-60, 60]\n",
    "        window_start = pos - window_size // 2\n",
    "        window_end = pos + window_size // 2\n",
    "        \n",
    "        # fragments which are outside of this [-60, 60], starts before -60 and ends after 60\n",
    "        spanning_count = 0\n",
    "        # fragments those either start or end in the window\n",
    "        internal_endpoints = 0\n",
    "        \n",
    "        for frag in fragment_data:\n",
    "            frag_start, frag_end, count = frag['start'], frag['end'], frag['count']\n",
    "            \n",
    "            # count spanning fragments\n",
    "            if frag_start <= window_start and frag_end >= window_end:\n",
    "                spanning_count += count\n",
    "            \n",
    "            # count internal endpoints\n",
    "            if window_start <= frag_start <= window_end:  # starting in the window\n",
    "                internal_endpoints += count\n",
    "            if window_start <= frag_end <= window_end:    # ending in the window\n",
    "                internal_endpoints += count\n",
    "        \n",
    "        lwps[pos_idx] = spanning_count - internal_endpoints\n",
    "    \n",
    "    return lwps\n",
    "\n",
    "lwps = calculate_lwps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(LWPS_UPPER_THRESHOLD, NUM_POSITIONS + LWPS_UPPER_THRESHOLD), lwps)\n",
    "plt.xlabel(\"Relative midpoint positions\")\n",
    "plt.ylabel(\"L-WPS score\")\n",
    "plt.title(\"Relative midpoint positions VS L-WPS score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_fragments_lengths = fragment_lengths[LWPS_LOWER_THRESHOLD:LWPS_UPPER_THRESHOLD + 1]\n",
    "plt.plot(np.arange(LWPS_LOWER_THRESHOLD, LWPS_UPPER_THRESHOLD + 1), filtered_fragments_lengths)\n",
    "plt.xlabel(\"Fragment lengths\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Fragment lengths distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(matrix):\n",
    "    X = 0.999\n",
    "    ENDPOINT_WINDOW = 10\n",
    "    WINDOW_SIZE = 20\n",
    "\n",
    "    logger.info(f\"Calculating FDI with x={X}, endpoint_window={ENDPOINT_WINDOW}, window_size={WINDOW_SIZE}\")\n",
    "\n",
    "    # convert matrix to reads format\n",
    "    reads = matrix_to_reads(matrix)\n",
    "    logger.info(f\"Converted matrix to {len(reads)} reads\")\n",
    "\n",
    "    # calculate coverage array\n",
    "    coverage = calculate_coverage(matrix)\n",
    "\n",
    "    # calculate endpoint dispersion matrix\n",
    "    dispersion_matrix = calculate_endpoint_dispersion(reads, matrix.shape[1], X, ENDPOINT_WINDOW)\n",
    "\n",
    "    # calculate FDI in non-overlapping sliding windows\n",
    "    fdi_results = calculate_windowed_fdi(coverage, dispersion_matrix, WINDOW_SIZE)\n",
    "\n",
    "    return fdi_results\n",
    "\n",
    "# # TODO: same logic as in LWPSStatistic\n",
    "def matrix_to_reads(matrix):    \n",
    "    reads = []\n",
    "    \n",
    "    for fragment_length in range(matrix.shape[0]):\n",
    "        # filtering out fragments based on lengths, maybe it makes sense\n",
    "        # if 120 <= fragment_length <= 180:\n",
    "        #     continue\n",
    "            \n",
    "        for rel_midpoint in range(matrix.shape[1]):\n",
    "            count = matrix[fragment_length, rel_midpoint]\n",
    "            \n",
    "            if count > 0:\n",
    "                frag_start = rel_midpoint - fragment_length // 2\n",
    "                frag_end = rel_midpoint + fragment_length // 2\n",
    "                \n",
    "                for _ in range(int(count)):\n",
    "                    reads.append({\n",
    "                        'start': frag_start,\n",
    "                        'end': frag_end,\n",
    "                        'count': count,\n",
    "                    })\n",
    "    return reads\n",
    "\n",
    "# TODO: same logic as in visualize_matrix.py\n",
    "def calculate_coverage(matrix: np.ndarray) -> np.ndarray:\n",
    "    matrix_columns = matrix.shape[1]\n",
    "    \n",
    "    coverage = np.zeros(matrix_columns)\n",
    "    \n",
    "    for fragment_length in range(matrix.shape[0]):\n",
    "        for rel_midpoint in range(matrix_columns):\n",
    "            count = matrix[fragment_length, rel_midpoint]\n",
    "            if count > 0:\n",
    "                # calculate start and end positions from midpoint and length\n",
    "                start_pos = rel_midpoint - fragment_length // 2\n",
    "                end_pos = rel_midpoint + fragment_length // 2\n",
    "                \n",
    "                # make sure we stay in our boundaries\n",
    "                start_pos = max(0, start_pos)\n",
    "                end_pos = min(matrix_columns, end_pos)\n",
    "                \n",
    "                # update coverage\n",
    "                if start_pos < end_pos:\n",
    "                    coverage[start_pos:end_pos] += count\n",
    "    \n",
    "    return coverage\n",
    "\n",
    "\n",
    "def calculate_endpoint_dispersion(reads, matrix_columns, x, endpoint_window):\n",
    "    # dispersion_matrix[:, 0] = endpoint counts, dispersion_matrix[:, 1] = dispersion values\n",
    "    dispersion_matrix = np.zeros((matrix_columns, 2))\n",
    "\n",
    "    # count endpoints at each position\n",
    "    for read in reads:\n",
    "        start, end, fragment_length = read['start'], read['end'], read['count']\n",
    "\n",
    "        # adjust positions to valid range\n",
    "        start = max(endpoint_window, min(start, matrix_columns - endpoint_window - 1))\n",
    "        end = max(endpoint_window, min(end, matrix_columns - endpoint_window - 1))\n",
    "\n",
    "        # count endpoints\n",
    "        dispersion_matrix[start, 0] += 1\n",
    "        dispersion_matrix[end, 0] += 1\n",
    "\n",
    "    # calculate dispersion values\n",
    "    for read in reads:\n",
    "        start, end, fragment_length = read['start'], read['end'], read['count']\n",
    "\n",
    "        # Adjust positions to valid range\n",
    "        start = max(endpoint_window, min(start, matrix_columns - endpoint_window - 1))\n",
    "        end = max(endpoint_window, min(end, matrix_columns - endpoint_window - 1))\n",
    "\n",
    "        # calculate local density and dispersion for start endpoint\n",
    "        local_density_start = np.sum(\n",
    "            dispersion_matrix[start-endpoint_window:start+endpoint_window+1, 0]\n",
    "        ) - 1\n",
    "        dispersion_matrix[start, 1] += x ** local_density_start\n",
    "\n",
    "        # calculate local density and dispersion for end endpoint  \n",
    "        local_density_end = np.sum(\n",
    "            dispersion_matrix[end-endpoint_window:end+endpoint_window+1, 0]\n",
    "        ) - 1\n",
    "        dispersion_matrix[end, 1] += x ** local_density_end\n",
    "\n",
    "    return dispersion_matrix\n",
    "\n",
    "def calculate_windowed_fdi(coverage, dispersion_matrix, window_size):\n",
    "    matrix_columns = len(coverage)\n",
    "    num_windows = matrix_columns // window_size\n",
    "\n",
    "    positions, fdi_scores, coverage_stds, endpoint_dispersions = [], [], [], []\n",
    "    for i in range(num_windows):\n",
    "        start = i * window_size\n",
    "        end = start + window_size\n",
    "\n",
    "        if not i % 10 or i == num_windows - 1:\n",
    "            progress = round(i / (num_windows - 1) * 100) if num_windows > 1 else 100\n",
    "            logger.info(f\"FDI calculation progress: {progress}%\")\n",
    "\n",
    "        # calculate coverage standard deviation in window\n",
    "        window_coverage = coverage[start:end]\n",
    "        coverage_std = np.std(window_coverage)\n",
    "\n",
    "        # calculate endpoint dispersion in window\n",
    "        window_endpoint_counts = np.sum(dispersion_matrix[start:end, 0])\n",
    "        if window_endpoint_counts == 0:  # avoid 0 division\n",
    "            window_endpoint_counts = 1\n",
    "\n",
    "        # calculate average endpoint dispersion\n",
    "        window_dispersion_sum = np.sum(dispersion_matrix[start:end, 1])\n",
    "        avg_endpoint_dispersion = window_dispersion_sum / window_endpoint_counts\n",
    "\n",
    "        # calculate FDI score\n",
    "        fdi_score = coverage_std * avg_endpoint_dispersion\n",
    "\n",
    "        positions.append((start, end))\n",
    "        fdi_scores.append(fdi_score)\n",
    "        coverage_stds.append(coverage_std)\n",
    "        endpoint_dispersions.append(avg_endpoint_dispersion)\n",
    "\n",
    "    return {\n",
    "        'positions': positions,\n",
    "        'fdi_scores': np.array(fdi_scores),\n",
    "        'coverage_std': np.array(coverage_stds),\n",
    "        'endpoint_dispersion': np.array(endpoint_dispersions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdi = calculate(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_centers = [(start + end) / 2 for start, end in fdi['positions']]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(window_centers, fdi['fdi_scores'], 'b-', marker='o', markersize=4, linewidth=1)\n",
    "\n",
    "# Mark the DHS site\n",
    "plt.axvline(x=1000, color='red', linestyle='--', linewidth=2, label='DHS site at 1000')\n",
    "\n",
    "# Use log scale for y-axis since values are very small\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('Genomic Position')\n",
    "plt.ylabel('FDI Score (log scale)')\n",
    "plt.title('FDI Scores Across Sliding Windows (DHS site at position 1000)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 0.99\n",
    "ENDPOINT_WINDOW = 10\n",
    "WINDOW_SIZE = 20\n",
    "\n",
    "reads = []\n",
    "for fragment_length in range(result.shape[0]):\n",
    "    for rel_midpoint in range(result.shape[1]):\n",
    "        count = result[fragment_length, rel_midpoint]\n",
    "        \n",
    "        if count > 0:\n",
    "            start_pos = rel_midpoint - fragment_length // 2\n",
    "            end_pos = start_pos + fragment_length\n",
    "\n",
    "            for _ in range(int(count)):\n",
    "                reads.append([start_pos, end_pos, fragment_length])\n",
    "\n",
    "reads = np.array(reads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "reads[:5], reads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = calculate_coverage(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage[:5], coverage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_matrix = np.zeros((MATRIX_COLUMNS, 2))\n",
    "\n",
    "# First pass: Count endpoints at each position\n",
    "# for read in np.concatenate([reads[:5], reads[-5:]], axis=0):\n",
    "for read in reads:\n",
    "    start_pos, end_pos, fragment_length = read\n",
    "\n",
    "    # Adjust positions to valid range\n",
    "    adjusted_start = max(ENDPOINT_WINDOW, min(start_pos, MATRIX_COLUMNS - ENDPOINT_WINDOW - 1))\n",
    "    adjusted_end = max(ENDPOINT_WINDOW, min(end_pos, MATRIX_COLUMNS - ENDPOINT_WINDOW - 1))\n",
    "    \n",
    "    # Count endpoints\n",
    "    density_matrix[adjusted_start, 0] += 1\n",
    "    density_matrix[adjusted_end, 0] += 1\n",
    "\n",
    "# # Second pass: Calculate dispersion values\n",
    "# for read in np.concatenate([reads[:5], reads[-5:]], axis=0):\n",
    "for read in reads:\n",
    "    start_pos, end_pos, fragment_length = read\n",
    "#     print(start_pos, end_pos)z\n",
    "\n",
    "    # Adjust positions to valid range\n",
    "    adjusted_start = max(ENDPOINT_WINDOW, min(start_pos, MATRIX_COLUMNS - ENDPOINT_WINDOW - 1))\n",
    "    adjusted_end = max(ENDPOINT_WINDOW, min(end_pos, MATRIX_COLUMNS - ENDPOINT_WINDOW - 1))\n",
    "#     print(adjusted_start, adjusted_end)\n",
    "    \n",
    "    local_density_start = np.sum(\n",
    "        density_matrix[adjusted_start - ENDPOINT_WINDOW: adjusted_start + ENDPOINT_WINDOW + 1, 0]\n",
    "    ) - 1\n",
    "    density_matrix[adjusted_start, 1] += X ** local_density_start\n",
    "#     print(local_density_start)\n",
    "    local_density_end = np.sum(\n",
    "        density_matrix[adjusted_end - ENDPOINT_WINDOW: adjusted_end + ENDPOINT_WINDOW + 1, 0]\n",
    "    ) - 1\n",
    "    density_matrix[adjusted_end, 1] += X ** local_density_end\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "density_matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx, end_idx = 100, len(density_matrix) - 100\n",
    "plt.plot(np.arange(start_idx, end_idx), density_matrix[start_idx:end_idx, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx, end_idx = 100, len(density_matrix) - 100\n",
    "plt.plot(np.arange(start_idx, end_idx), density_matrix[start_idx:end_idx, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_columns = len(coverage)\n",
    "num_windows = matrix_columns // WINDOW_SIZE\n",
    "\n",
    "positions = []\n",
    "fdi_scores = []\n",
    "coverage_stds = []\n",
    "endpoint_dispersions = []\n",
    "\n",
    "for i in range(num_windows):\n",
    "    start = i * WINDOW_SIZE\n",
    "    end = start + WINDOW_SIZE\n",
    "    \n",
    "    if not i % 10 or i == num_windows - 1:\n",
    "        progress = round(i / (num_windows - 1) * 100) if num_windows > 1 else 100\n",
    "        logger.info(f\"FDI calculation progress: {progress}%\")\n",
    "\n",
    "    # calculate coverage standard deviation in window\n",
    "    window_coverage = coverage[start:end]\n",
    "    coverage_std = np.std(window_coverage)\n",
    "\n",
    "    # calculate endpoint dispersion in window\n",
    "    window_endpoint_counts = np.sum(density_matrix[start:end, 0])\n",
    "    if window_endpoint_counts == 0:  # avoid 0 division\n",
    "        window_endpoint_counts = 1\n",
    "\n",
    "    # calculate average endpoint dispersion\n",
    "    window_dispersion_sum = np.sum(density_matrix[start:end, 1])\n",
    "    avg_endpoint_dispersion = window_dispersion_sum / window_endpoint_counts\n",
    "\n",
    "    # calculate FDI score\n",
    "    fdi_score = coverage_std * avg_endpoint_dispersion\n",
    "\n",
    "    positions.append((start, end))\n",
    "    fdi_scores.append(fdi_score)\n",
    "    coverage_stds.append(coverage_std)\n",
    "    endpoint_dispersions.append(avg_endpoint_dispersion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdi_results = np.zeros(matrix_columns)\n",
    "for i, (start, end) in enumerate(positions):\n",
    "    print(i, start, end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
